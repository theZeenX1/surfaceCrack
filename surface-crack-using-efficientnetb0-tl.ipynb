{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm\nimport os\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport ipywidgets as widgets\nimport io\nfrom PIL import Image\nfrom IPython.display import display,clear_output\nfrom warnings import filterwarnings\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-01-28T16:35:32.564925Z","iopub.execute_input":"2023-01-28T16:35:32.565260Z","iopub.status.idle":"2023-01-28T16:35:40.245986Z","shell.execute_reply.started":"2023-01-28T16:35:32.565159Z","shell.execute_reply":"2023-01-28T16:35:40.244881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\ncolors_red = [\"#331313\", \"#582626\", '#9E1717', '#D35151', '#E9B4B4']\ncolors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']\n\nsns.palplot(colors_dark)\nsns.palplot(colors_green)\nsns.palplot(colors_red)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:35:40.248357Z","iopub.execute_input":"2023-01-28T16:35:40.249400Z","iopub.status.idle":"2023-01-28T16:35:40.533440Z","shell.execute_reply.started":"2023-01-28T16:35:40.249358Z","shell.execute_reply":"2023-01-28T16:35:40.532033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"mentioning the labels in a list","metadata":{}},{"cell_type":"code","source":"labels=['Negative','Positive']","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:35:40.539989Z","iopub.execute_input":"2023-01-28T16:35:40.540819Z","iopub.status.idle":"2023-01-28T16:35:40.551693Z","shell.execute_reply.started":"2023-01-28T16:35:40.540756Z","shell.execute_reply":"2023-01-28T16:35:40.549080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = []\ny_train = []\nimage_size = 400\nfor i in labels:\n    folderPath = os.path.join('/kaggle/input/surface-crack','train',i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(image_size, image_size))\n        X_train.append(img)\n        y_train.append(i)\nfor i in labels:\n    folderPath = os.path.join('/kaggle/input/surface-crack','valid',i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(image_size,image_size))\n        X_train.append(img)\n        y_train.append(i)\nfor i in labels:\n    folderPath = os.path.join('/kaggle/input/surface-crack','test',i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(image_size,image_size))\n        X_train.append(img)\n        y_train.append(i)\nX_train = np.array(X_train)\ny_train = np.array(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:35:40.555919Z","iopub.execute_input":"2023-01-28T16:35:40.556507Z","iopub.status.idle":"2023-01-28T16:35:47.163882Z","shell.execute_reply.started":"2023-01-28T16:35:40.556467Z","shell.execute_reply":"2023-01-28T16:35:47.162757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k=0\nfig, ax = plt.subplots(1,2,figsize=(20,20))\nfig.text(s='Sample Image From Each Label',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=0.62,x=0.4,alpha=0.8)\nfor i in labels:\n    j=0\n    while True :\n        if y_train[j]==i:\n            ax[k].imshow(X_train[j])\n            ax[k].set_title(y_train[j])\n            ax[k].axis('off')\n            k+=1\n            break\n        j+=1","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:35:47.165540Z","iopub.execute_input":"2023-01-28T16:35:47.166045Z","iopub.status.idle":"2023-01-28T16:35:47.761990Z","shell.execute_reply.started":"2023-01-28T16:35:47.166009Z","shell.execute_reply":"2023-01-28T16:35:47.759435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = shuffle(X_train,y_train, random_state=101)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:35:47.763004Z","iopub.execute_input":"2023-01-28T16:35:47.763345Z","iopub.status.idle":"2023-01-28T16:35:47.914485Z","shell.execute_reply.started":"2023-01-28T16:35:47.763314Z","shell.execute_reply":"2023-01-28T16:35:47.913524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"splitting the images into train and test respectively","metadata":{}},{"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.1,random_state=101)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:35:47.915874Z","iopub.execute_input":"2023-01-28T16:35:47.916232Z","iopub.status.idle":"2023-01-28T16:35:48.028242Z","shell.execute_reply.started":"2023-01-28T16:35:47.916198Z","shell.execute_reply":"2023-01-28T16:35:48.027127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One hot encoding this shit","metadata":{}},{"cell_type":"code","source":"y_train_new = []\nfor i in y_train:\n    y_train_new.append(labels.index(i))\ny_train = y_train_new\ny_train = tf.keras.utils.to_categorical(y_train)\n\n\ny_test_new = []\nfor i in y_test:\n    y_test_new.append(labels.index(i))\ny_test = y_test_new\ny_test = tf.keras.utils.to_categorical(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:35:48.029500Z","iopub.execute_input":"2023-01-28T16:35:48.029886Z","iopub.status.idle":"2023-01-28T16:35:48.037929Z","shell.execute_reply.started":"2023-01-28T16:35:48.029849Z","shell.execute_reply":"2023-01-28T16:35:48.036922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Transfer learning using EfficientNet \n\nA way to short-cut this process is to re-use the model weights from pre-trained models that were developed for standard computer vision benchmark datasets, such as the ImageNet image recognition tasks. Top performing models can be downloaded and used directly, or integrated into a new model for your own computer vision problems.\n\nIn this notebook, I'll be using the EfficientNetB0 model which will use the weights from the ImageNet dataset.\n\nThe include_top parameter is set to False so that the network doesn't include the top layer/ output layer from the pre-built model which allows us to add our own output layer depending upon our use case!","metadata":{}},{"cell_type":"code","source":"effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:35:48.039443Z","iopub.execute_input":"2023-01-28T16:35:48.040284Z","iopub.status.idle":"2023-01-28T16:35:53.412506Z","shell.execute_reply.started":"2023-01-28T16:35:48.040210Z","shell.execute_reply":"2023-01-28T16:35:53.411545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"head for predicting the output from the transfer learning pretrained model","metadata":{}},{"cell_type":"code","source":"model = effnet.output\nmodel = tf.keras.layers.GlobalAveragePooling2D()(model)\nmodel = tf.keras.layers.Dropout(rate=0.5)(model)\nmodel = tf.keras.layers.Dense(2,activation='softmax')(model)\nmodel = tf.keras.models.Model(inputs=effnet.input, outputs = model)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:35:53.416548Z","iopub.execute_input":"2023-01-28T16:35:53.416879Z","iopub.status.idle":"2023-01-28T16:35:53.452879Z","shell.execute_reply.started":"2023-01-28T16:35:53.416850Z","shell.execute_reply":"2023-01-28T16:35:53.452042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"summary of the final model","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"_kg_hide-input":true,"scrolled":true,"execution":{"iopub.status.busy":"2023-01-28T16:35:53.454207Z","iopub.execute_input":"2023-01-28T16:35:53.454544Z","iopub.status.idle":"2023-01-28T16:35:53.486018Z","shell.execute_reply.started":"2023-01-28T16:35:53.454511Z","shell.execute_reply":"2023-01-28T16:35:53.484738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:35:53.487979Z","iopub.execute_input":"2023-01-28T16:35:53.488630Z","iopub.status.idle":"2023-01-28T16:35:53.505577Z","shell.execute_reply.started":"2023-01-28T16:35:53.488594Z","shell.execute_reply":"2023-01-28T16:35:53.504563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Callbacks -> Callbacks can help you fix bugs more quickly, and can help you build better models. They can help you visualize how your modelâ€™s training is going, and can even help prevent overfitting by implementing early stopping or customizing the learning rate on each iteration.\n\nBy definition, \"A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training.\"\n\nIn this notebook, I'll be using TensorBoard, ModelCheckpoint and ReduceLROnPlateau callback functions","metadata":{}},{"cell_type":"code","source":"tensorboard = TensorBoard(log_dir = 'logs')\ncheckpoint = ModelCheckpoint(\"effnet.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n                              mode='auto',verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:35:53.506860Z","iopub.execute_input":"2023-01-28T16:35:53.507264Z","iopub.status.idle":"2023-01-28T16:35:54.118021Z","shell.execute_reply.started":"2023-01-28T16:35:53.507226Z","shell.execute_reply":"2023-01-28T16:35:54.117016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train,y_train,validation_split=0.1, epochs =12, verbose=1, batch_size=32,\n                   callbacks=[tensorboard,checkpoint,reduce_lr])","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2023-01-28T16:35:54.119575Z","iopub.execute_input":"2023-01-28T16:35:54.120659Z","iopub.status.idle":"2023-01-28T16:41:23.115927Z","shell.execute_reply.started":"2023-01-28T16:35:54.120620Z","shell.execute_reply":"2023-01-28T16:41:23.114950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filterwarnings('ignore')\n\nepochs = [i for i in range(12)]\nfig, ax = plt.subplots(1,2,figsize=(14,7))\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nfig.text(s='Epochs vs. Training and Validation Accuracy/Loss',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=1,x=0.28,alpha=0.8)\n\nsns.despine()\nax[0].plot(epochs, train_acc, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label = 'Training Accuracy')\nax[0].plot(epochs, val_acc, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Accuracy')\nax[0].legend(frameon=False)\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Accuracy')\n\nsns.despine()\nax[1].plot(epochs, train_loss, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label ='Training Loss')\nax[1].plot(epochs, val_loss, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Loss')\nax[1].legend(frameon=False)\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Training & Validation Loss')\n\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:41:23.118943Z","iopub.execute_input":"2023-01-28T16:41:23.119262Z","iopub.status.idle":"2023-01-28T16:41:23.780289Z","shell.execute_reply.started":"2023-01-28T16:41:23.119233Z","shell.execute_reply":"2023-01-28T16:41:23.779322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"argmax function as each row from the prediction array contains tqo  values for the respective labels. The maximum value which is in each row depicts the predicted output out of the 2 possible outcomes.\nSo with argmax, I'm able to find out the index associated with the predicted outcome.","metadata":{}},{"cell_type":"code","source":"pred = model.predict(X_test)\npred = np.argmax(pred,axis=1)\ny_test_new = np.argmax(y_test,axis=1)\nprint(type(X_test))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-01-28T16:41:23.781807Z","iopub.execute_input":"2023-01-28T16:41:23.785040Z","iopub.status.idle":"2023-01-28T16:41:26.160959Z","shell.execute_reply.started":"2023-01-28T16:41:23.784983Z","shell.execute_reply":"2023-01-28T16:41:26.159902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test_new,pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:41:26.164017Z","iopub.execute_input":"2023-01-28T16:41:26.164385Z","iopub.status.idle":"2023-01-28T16:41:26.176389Z","shell.execute_reply.started":"2023-01-28T16:41:26.164332Z","shell.execute_reply":"2023-01-28T16:41:26.175170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_test_new)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:41:26.177863Z","iopub.execute_input":"2023-01-28T16:41:26.178448Z","iopub.status.idle":"2023-01-28T16:41:26.185255Z","shell.execute_reply.started":"2023-01-28T16:41:26.178410Z","shell.execute_reply":"2023-01-28T16:41:26.184012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv_img(image):\n    image = np.array(image)\n    x_i = image.shape[0]\n    y_i = image.shape[1]\n\n    x = 0\n    y = 0\n    final = []\n    while y + image_size <= y_i:\n        x = 0\n        while x + image_size <= x_i: \n            shrt = []\n            for i in range(x, x + image_size, 1):\n                shrtx = []\n                for j in range(y, y + image_size, 1):\n                    shrtx.append(image[i][j])\n                shrt.append(shrtx)\n            x += 100\n            final.append(shrt)\n        y += 100\n#     for image in final:\n#         display_image(image)\n    final = np.array(final)\n    return final","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:41:26.186831Z","iopub.execute_input":"2023-01-28T16:41:26.188501Z","iopub.status.idle":"2023-01-28T16:41:26.197675Z","shell.execute_reply.started":"2023-01-28T16:41:26.188016Z","shell.execute_reply":"2023-01-28T16:41:26.196564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def search_crack(img_array):\n    img_breakdown = conv_img(img_array)\n    pred = model.predict(img_breakdown)\n    pred = np.argmax(pred,axis=1)\n    y_test_new = np.argmax(y_test,axis=1)\n    predict = 0\n    for i in y_test_new:\n        if i == 1: predict = 1\n    return predict","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:41:26.199446Z","iopub.execute_input":"2023-01-28T16:41:26.200238Z","iopub.status.idle":"2023-01-28T16:41:26.209103Z","shell.execute_reply.started":"2023-01-28T16:41:26.200191Z","shell.execute_reply":"2023-01-28T16:41:26.207247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_predict = []\npath = '/kaggle/input/surface-crack/predict'\nfor img in os.listdir(path):\n    img_array = cv2.imread(os.path.join(path, img))\n    img_array = cv2.resize(img_array, (1000, 1000))\n    img_predict.append(img_array)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:41:26.210635Z","iopub.execute_input":"2023-01-28T16:41:26.211262Z","iopub.status.idle":"2023-01-28T16:41:27.876520Z","shell.execute_reply.started":"2023-01-28T16:41:26.211218Z","shell.execute_reply":"2023-01-28T16:41:27.875456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_image(image):\n    plt.figure(figsize=(20,20))\n    plt.imshow(image, cmap = 'gray')\n    plt.show()\n    \nfor img in img_predict:\n    display_image(img)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-01-28T16:41:27.877836Z","iopub.execute_input":"2023-01-28T16:41:27.878183Z","iopub.status.idle":"2023-01-28T16:41:33.859631Z","shell.execute_reply.started":"2023-01-28T16:41:27.878150Z","shell.execute_reply":"2023-01-28T16:41:33.858525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor img in tqdm(img_predict):\n    temp = search_crack(img)\n    predictions.append(temp)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-01-28T16:41:33.860928Z","iopub.execute_input":"2023-01-28T16:41:33.861964Z","iopub.status.idle":"2023-01-28T16:42:15.021139Z","shell.execute_reply.started":"2023-01-28T16:41:33.861927Z","shell.execute_reply":"2023-01-28T16:42:15.020102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2023-01-28T16:42:15.022768Z","iopub.execute_input":"2023-01-28T16:42:15.023795Z","iopub.status.idle":"2023-01-28T16:42:15.031122Z","shell.execute_reply.started":"2023-01-28T16:42:15.023753Z","shell.execute_reply":"2023-01-28T16:42:15.030046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}